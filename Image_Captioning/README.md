## Image Captioning
### CVPR2015
\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2015/papers/Fang_From_Captions_to_2015_CVPR_paper.pdf) From Captions to Visual Concepts and Back

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2015/papers/Chen_Minds_Eye_A_2015_CVPR_paper.pdf) Mind's Eye: A Recurrent Visual Representation for Image Caption Generation

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf) Show and Tell: A Neural Image Caption Generator

### ICCV2015
\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_iccv_2015/papers/Jia_Guiding_the_Long-Short_ICCV_2015_paper.pdf) Guiding the Long-Short Term Memory Model for Image Caption Generation

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_iccv_2015/papers/Ushiku_Common_Subspace_for_ICCV_2015_paper.pdf) Common Subspace for Model and Similarity: Phrase Learning for Caption Generation From Images

### CVPR2016
\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2016/papers/Hendricks_Deep_Compositional_Captioning_CVPR_2016_paper.pdf) Deep Compositional Captioning: Describing Novel Object Categories Without Paired Training Data

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2016/papers/Pan_Hierarchical_Recurrent_Neural_CVPR_2016_paper.pdf) Hierarchical Recurrent Neural Encoder for Video Representation With Application to Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2016/papers/Johnson_DenseCap_Fully_Convolutional_CVPR_2016_paper.pdf) DenseCap: Fully Convolutional Localization Networks for Dense Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2016/papers/Yu_Video_Paragraph_Captioning_CVPR_2016_paper.pdf) Video Paragraph Captioning Using Hierarchical Recurrent Neural Networks

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2016/papers/Mustafa_Temporally_Coherent_4D_CVPR_2016_paper.pdf) Image Captioning With Semantic Attention

### ECCV2016
\[NOTES\] \[PDF\] Leveraging Visual Question Answering for Image-Caption Ranking

\[NOTES\] \[PDF\] SPICE: Semantic Propositional Image Caption Evaluation

### AAAI2016
None...

### CVPR2017
[\[NOTES\]](Image_Captioning/Show_Attend_and_Tell) [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Ren_Deep_Reinforcement_Learning-Based_CVPR_2017_paper.pdf) Deep Reinforcement Learning-Based Image Captioning With Embedding Reward

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Lu_Knowing_When_to_CVPR_2017_paper.pdf) Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Park_Attend_to_You_CVPR_2017_paper.pdf) Attend to You: Personalized Image Captioning With Context Sequence Memory Networks

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Gan_Semantic_Compositional_Networks_CVPR_2017_paper.pdf) Semantic Compositional Networks for Visual Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Rennie_Self-Critical_Sequence_Training_CVPR_2017_paper.pdf) Self-Critical Sequence Training for Image Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Chen_SCA-CNN_Spatial_and_CVPR_2017_paper.pdf) SCA-CNN: Spatial and Channel-Wise Attention in Convolutional Networks for Image Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Venugopalan_Captioning_Images_With_CVPR_2017_paper.pdf) Captioning Images With Diverse Objects

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_Skeleton_Key_Image_CVPR_2017_paper.pdf) Skeleton Key: Image Captioning by Skeleton-Attribute Decomposition

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Yao_Incorporating_Copying_Mechanism_CVPR_2017_paper.pdf) Incorporating Copying Mechanism in Image Captioning for Learning Novel Objects

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Sun_Bidirectional_Beam_Search_CVPR_2017_paper.pdf) Bidirectional Beam Search: Forward-Backward Inference in Neural Sequence Models for Fill-In-The-Blank

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Baraldi_Hierarchical_Boundary-Aware_Neural_CVPR_2017_paper.pdf) Hierarchical Boundary-Aware Neural Encoder for Video Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Yu_Supervising_Neural_Attention_CVPR_2017_paper.pdf) Supervising Neural Attention Models for Video Captioning by Human Gaze Data

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Shen_Weakly_Supervised_Dense_CVPR_2017_paper.pdf) Weakly Supervised Dense Video Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Yang_Dense_Captioning_With_CVPR_2017_paper.pdf) Dense Captioning With Joint Inference and Visual Context

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Yu_End-To-End_Concept_Word_CVPR_2017_paper.pdf) End-To-End Concept Word Detection for Video Captioning, Retrieval, and Question Answering

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2017/papers/Pan_Video_Captioning_With_CVPR_2017_paper.pdf) Video Captioning With Transferred Semantic Attributes

### ICCV2017
\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Chen_Show_Adapt_and_ICCV_2017_paper.pdf) Show, Adapt and Tell: Adversarial Training of Cross-Domain Image Captioner

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Krishna_Dense-Captioning_Events_in_ICCV_2017_paper.pdf) Dense-Captioning Events in Videos

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Liu_Improved_Image_Captioning_ICCV_2017_paper.pdf) Improved Image Captioning via Policy Gradient Optimization of SPIDEr

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Gu_An_Empirical_Study_ICCV_2017_paper.pdf) An Empirical Study of Language CNN for Image Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Pedersoli_Areas_of_Attention_ICCV_2017_paper.pdf) Areas of Attention for Image Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Li_Scene_Graph_Generation_ICCV_2017_paper.pdf) Scene Graph Generation From Objects, Phrases and Region Captions

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Marwah_Attentive_Semantic_Video_ICCV_2017_paper.pdf) Attentive Semantic Video Generation Using Captions

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Tavakoli_Paying_Attention_to_ICCV_2017_paper.pdf) Paying Attention to Descriptions Generated by Image Captioning Models

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Shetty_Speaking_the_Same_ICCV_2017_paper.pdf) Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Yao_Boosting_Image_Captioning_ICCV_2017_paper.pdf) Boosting Image Captioning With Attributes

### AAAI2017
\[NOTES\] \[PDF\] Reference	Based	LSTM for	Image	Captioning

\[NOTES\] \[PDF\] Image Caption with Global-Local Attention

\[NOTES\] \[PDF\] Attention	Correctness: Machine Perception vs Human	Annotations	in	Neural Image Captioning

\[NOTES\] \[PDF\] Text-guided	Attention	Model	for	Image	Captioning

\[NOTES\] \[PDF\] Video	Captioning	with	Listwise	Supervision

\[NOTES\] \[PDF\] A	Deep Learning Approach for Arabic Caption Generation using	Roots-Words Vasu Jindal

### CVPR2018
\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_GroupCap_Group-Based_Image_CVPR_2018_paper.pdf) GroupCap: Group-Based Image Captioning With Structured Relevance and Diversity Constraints

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Video_Captioning_via_CVPR_2018_paper.pdf) Video Captioning via Hierarchical Reinforcement Learning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Aneja_Convolutional_Image_Captioning_CVPR_2018_paper.pdf) Convolutional Image Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Cui_Learning_to_Evaluate_CVPR_2018_paper.pdf) Learning to Evaluate Image Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_Fine-Grained_Video_Captioning_CVPR_2018_paper.pdf) Fine-Grained Video Captioning for Sports Narrative

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Anderson_Bottom-Up_and_Top-Down_CVPR_2018_paper.pdf) Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wu_Interpretable_Video_Captioning_CVPR_2018_paper.pdf) Interpretable Video Captioning via Trajectory Structured Localization

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Luo_Discriminability_Objective_for_CVPR_2018_paper.pdf) Discriminability Objective for Training Descriptive Captions

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Bidirectional_Attentive_Fusion_CVPR_2018_paper.pdf) Bidirectional Attentive Fusion With Context Gating for Dense Video Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Jointly_Localizing_and_CVPR_2018_paper.pdf) Jointly Localizing and Describing Events for Dense Video Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_M3_Multimodal_Memory_CVPR_2018_paper.pdf) M3: Multimodal Memory Modelling for Video Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Reconstruction_Network_for_CVPR_2018_paper.pdf) Reconstruction Network for Video Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_Regularizing_RNNs_for_CVPR_2018_paper.pdf) Regularizing RNNs for Caption Generation by Reconstructing the Past With the Present

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Mathews_SemStyle_Learning_to_CVPR_2018_paper.pdf) SemStyle: Learning to Generate Stylised Image Captions Using Unaligned Text

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhou_End-to-End_Dense_Video_CVPR_2018_paper.pdf) End-to-End Dense Video Captioning With Masked Transformer

### ECCV2018
\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ECCV_2018/papers/Shi_Chen_Boosted_Attention_Leveraging_ECCV_2018_paper.pdf) Boosted Attention: Leveraging Human Attention for Image Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ECCV_2018/papers/Yangyu_Chen_Less_is_More_ECCV_2018_paper.pdf) Less is More: Picking Informative Frames for Video Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ECCV_2018/papers/Xihui_Liu_Show_Tell_and_ECCV_2018_paper.pdf) Show, Tell and Discriminate: Image Captioning by Self-retrieval with Partially Labeled Data

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ECCV_2018/papers/Jiuxiang_Gu_Unpaired_Image_Captioning_ECCV_2018_paper.pdf) Unpaired Image Captioning by Language Pivoting

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ECCV_2018/papers/Bo_Dai_Rethinking_the_Form_ECCV_2018_paper.pdf) Rethinking the Form of Latent States in Image Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ECCV_2018/papers/Lisa_Anne_Hendricks_Women_also_Snowboard_ECCV_2018_paper.pdf) Women also Snowboard: Overcoming Bias in Captioning Models

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ECCV_2018/papers/Naeha_Sharif_NNEval_Neural_Network_ECCV_2018_paper.pdf) NNEval: Neural Network based Evaluation Metric for Image Captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ECCV_2018/papers/Wenhao_Jiang_Recurrent_Fusion_Network_ECCV_2018_paper.pdf) Recurrent Fusion Network for Image captioning

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ECCV_2018/papers/Tianlang_Chen_Factual_or_Emotional_ECCV_2018_paper.pdf) \'Factual\' or \'Emotional\': Stylized Image Captioning with Adaptive Learning and Attention

\[NOTES\] [\[PDF\]](http://openaccess.thecvf.com/content_ECCV_2018/papers/Ting_Yao_Exploring_Visual_Relationship_ECCV_2018_paper.pdf) Exploring Visual Relationship for Image Captioning

### AAAI2018
\[NOTES\] \[PDF\] Integrating both Visual and Audio Cues for Enhanced Video Caption

\[NOTES\] \[PDF\] Learning to Guide Decoding for Image Captionin

\[NOTES\] \[PDF\] Stack-Captioning: Coarse-to-Fine Learning for Image Captioning

\[NOTES\] \[PDF\] Temporal-difference Learning with Sampling Baseline for Image Captioning

### CVPR2019
Coming Soon...

### AAAI2019
\[NOTES\] \[PDF\] Hierarchical Attention Network for Image Captioning

\[NOTES\] \[PDF\] Learning to Compose Topic-Aware Mixture of Experts for Zero-Shot Video Captioning

\[NOTES\] \[PDF\] Temporal Deformable Convolutional Encoder-Decoder Networks for Video Captioning

\[NOTES\] \[PDF\] Fully Convolutional Video Captioning with Coarse-to-Fine and Inherited Attention

\[NOTES\] \[PDF\] Motion Guided Spatial Attention for Video Captioning

\[NOTES\] \[PDF\] Learning Object Context for Dense Captioning

\[NOTES\] \[PDF\] Connecting Language to Images: A Progressive Attention-Guided Network for Simultaneous Image Captioning and Language Grounding

\[NOTES\] \[PDF\] Meta Learning for Image Captioning

\[NOTES\] \[PDF\] Improving Image Captioning with Conditional Generative Adversarial Nets

\[NOTES\] \[PDF\] Deliberate Residual based Attention Network for Image Captioning
